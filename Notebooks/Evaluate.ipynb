{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.misc\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "image = tf.keras.preprocessing.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer_classes = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/maxim/notebooks/ObjectRecognition/datasets'\n",
    "\n",
    "def get_path(path):\n",
    "    return os.path.join(base_path, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(get_path('devkit/cars_meta.mat'))\n",
    "label_names = np.array([row[0] for row in mat['class_names'].reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(get_path('devkit/cars_annos.mat'))\n",
    "file_labels = {row[0][0]: row[5].squeeze() - 1 for row in mat['annotations'][0]}\n",
    "\n",
    "filenames_np = np.array([get_path(row[0][0]) for row in mat['annotations'][0]])\n",
    "\n",
    "labels_np = np.array([row[5].squeeze() - 1 for row in mat['annotations'][0]])\n",
    "labels_one_hot = np.zeros((labels_np.size, output_layer_classes))\n",
    "labels_one_hot[np.arange(labels_np.size), labels_np] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train_np, filenames_test_np, labels_train_np, labels_test_np = \\\n",
    "    train_test_split(filenames_np, labels_one_hot, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train = tf.constant(filenames_train_np)\n",
    "labels_train = tf.constant(labels_train_np)\n",
    "filenames_test = tf.constant(filenames_test_np)\n",
    "labels_test = tf.constant(labels_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((filenames_train, labels_train))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((filenames_test, labels_test))\n",
    "\n",
    "image_count = int(filenames_train.shape[0])\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 64\n",
    "STEPS_PER_EPOCH = np.ceil(2 * image_count / BATCH_SIZE)\n",
    "\n",
    "\n",
    "def convert(filename, label):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=CHANNELS)\n",
    "     # img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = (img/127.5) - 1\n",
    "    img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    return img, label\n",
    "\n",
    "def augment(filename, label):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=CHANNELS)\n",
    "     # img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = (img / 127.5) - 1\n",
    "    img = tf.image.resize(img, [2 * IMG_WIDTH, 2 * IMG_HEIGHT])\n",
    "    \n",
    "    img = tf.image.random_crop(img, size=[IMG_WIDTH, IMG_HEIGHT, CHANNELS]) # Random crop back to 28x28\n",
    "    img = tf.image.random_brightness(img, max_delta=0.5) # Random brightness\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "\n",
    "    return img,label\n",
    "\n",
    "database_train1 = dataset_train.map(convert)\n",
    "database_train2 = dataset_train.map(augment)\n",
    "database_train = database_train1.concatenate(database_train2)\n",
    "\n",
    "database_test = dataset_test.map(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(label_names[label_batch[n]])\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(database_train, cache='cache')\n",
    "test_ds = prepare_for_training(database_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = load_model('cars_full_aug12_double_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Audi A5 Coupe 2012'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img_path = get_path('AUDI-A5-2.jpg')\n",
    "img = image.load_img(img_path, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x / 127.5 - 1\n",
    "print('Input image shape:', x.shape)\n",
    "#my_image = scipy.misc.imread(img_path)\n",
    "#imshow(my_image)\n",
    "#print(\"class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \")\n",
    "pred = np.array(model.predict(x)).reshape(-1)\n",
    "label_names[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2= tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(filename):\n",
    "    img_path = get_path(filename)\n",
    "    img = image.load_img(img_path, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x / 127.5 - 1\n",
    "    #print(x)\n",
    "    return np.array(model2.predict(x)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as sla\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hummer1 = vectorize('hummer1.jpg')\n",
    "hummer2 = vectorize('hummer2.jpg')\n",
    "audi1 = vectorize('AUDI-A5.jpg')\n",
    "audi2 = vectorize('AUDI-A5-2.jpg')\n",
    "camry1 = vectorize('camry.jpg')\n",
    "camry2 = vectorize('camry2.jpg')\n",
    "mb = vectorize('mercedes-e-classe.jpg')\n",
    "santafe1 = vectorize('hyundai-santa-fe.jpg')\n",
    "santafe2 = vectorize('santafe2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.39241409301758, 0.9359222948551178)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.norm(hummer2 - audi2), spatial.distance.cosine(hummer2, audi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.20895004272461, 0.7749945968389511)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.norm(hummer1 - audi1), spatial.distance.cosine(hummer1, audi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27.448389053344727, 0.4050180912017822)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.norm(audi2 - audi1), spatial.distance.cosine(audi2, audi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.293447494506836, 0.2614699602127075)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.norm(hummer2 - hummer1), spatial.distance.cosine(hummer2, hummer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.337045669555664, 0.7573308944702148)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.norm(hummer1 - camry1), spatial.distance.cosine(hummer1, camry1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.24966049194336, 0.2142622470855713)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.norm(camry1 - camry2), spatial.distance.cosine(camry1, camry2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.648765563964844, 0.4753033518791199)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.norm(santafe1 - mb), spatial.distance.cosine(santafe1, mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.84998893737793, 0.5186568796634674)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.norm(santafe2 - mb), spatial.distance.cosine(santafe2, mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.136764526367188, 0.1515343189239502)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.norm(santafe2 - santafe1), spatial.distance.cosine(santafe2, santafe1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hummer1.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
